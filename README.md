# üßæ Evolu√ß√£o de Software 2025-2

### Equipe 4

01 - Carlos Eduardo Dias dos Santos - 202100104941  
02 - D√©borah Abreu Sales - 202100060758  
03 - Eduardo Afonso Passos Silva - 201800102096  
04 - Guilherme Ilan Barboza Carvalho - 201900051196  
05 - Marcelo Venicius Almeida Lima - 202000012981  
06 - Mikael Douglas Santos Farias - 201700053275  
07 - Ra√≠ Rafael Santos Silva ‚Äì 202000138043  
08 - Matheus Soares Santana - 201800147786

# üîç An√°lise de Code Smells com LLMs

Este reposit√≥rio cont√©m a **pipeline automatizada de an√°lise de code smells** desenvolvida como parte de uma atividade acad√™mica, utilizando **modelos de linguagem de grande porte (LLMs)** para identificar problemas de qualidade de c√≥digo com base **exclusiva na taxonomia do Refactoring Guru**.

A an√°lise foi conduzida sobre o projeto **[mastra-ai/mastra](https://github.com/mastra-ai/mastra)**, considerando m√∫ltiplas releases do reposit√≥rio e diferentes modelos de linguagem, com foco na **evolu√ß√£o da qualidade do software**.

---

## üìå Objetivo

O objetivo desta atividade √©:

- Identificar *code smells* no projeto selecionado pela equipe na Atividade 1, usando a taxonomia do **Refactoring Guru**.
- Utilizar **tr√™s modelos de linguagem diferentes** da plataforma **Hugging Face** para analisar o c√≥digo-fonte.
- Comparar os resultados obtidos pelos modelos, avaliando a precis√£o e as justificativas t√©cnicas.
- Avaliar a **efetividade dos modelos de linguagem** na identifica√ß√£o de *code smells*.
- Analisar a **evolu√ß√£o da qualidade do c√≥digo** ao longo das releases do projeto.
- **Documentar todo o processo experimental** e disponibilizar no **GitHub**.
- Produzir um **tutorial em PDF** e um **v√≠deo explicativo** sobre o processo e os resultados.

---

## üß† Taxonomia de Code Smells

A an√°lise segue **estritamente** a taxonomia definida pelo portal **Refactoring Guru**, limitada √†s seguintes categorias:

- **Bloaters**
- **Object-Orientation Abusers**
- **Change Preventers**
- **Dispensables**
- **Couplers**

‚ö†Ô∏è N√£o s√£o utilizados sin√¥nimos, categorias alternativas ou classifica√ß√µes externas.

---

## üß™ Ambiente de Execu√ß√£o

A pipeline foi desenvolvida e executada no ambiente **Google Colab (Free Tier)**, escolhido por sua acessibilidade e facilidade de reprodu√ß√£o dos experimentos.

### Limita√ß√µes consideradas:
- Mem√≥ria RAM limitada
- Tempo m√°ximo de execu√ß√£o da sess√£o
- Poss√≠veis desconex√µes inesperadas

Essas restri√ß√µes motivaram decis√µes de projeto voltadas √† **execu√ß√£o incremental**, **persist√™ncia frequente dos resultados** e **processamento em lotes (batching)**.

---

## üîê Gerenciamento Seguro do Token do Hugging Face

O acesso aos modelos de linguagem √© realizado por meio de autentica√ß√£o na plataforma **Hugging Face**.

Para garantir seguran√ßa:
- O token de acesso √© armazenado utilizando o recurso **Secrets do Google Colab**
- O token √© referenciado apenas pela vari√°vel de ambiente `HF_TOKEN`
- Nenhuma credencial sens√≠vel √© versionada ou exposta no reposit√≥rio

---

## ‚öôÔ∏è Pipeline de An√°lise

A pipeline foi implementada em Python e estruturada nas seguintes etapas:

1. **Instala√ß√£o din√¢mica das depend√™ncias**
2. **Autentica√ß√£o no Hugging Face**
3. **Clonagem do reposit√≥rio do projeto analisado**
4. **Sele√ß√£o das releases (tags)**
5. **Coleta dos arquivos-fonte relevantes**
6. **An√°lise assistida por modelos de linguagem**
7. **Persist√™ncia incremental dos resultados**
8. **Consolida√ß√£o final em arquivo JSON**

Cada modelo √© executado de forma **independente**, evitando carregamento simult√¢neo e reduzindo o consumo de mem√≥ria.

---

## üìÇ Sele√ß√£o dos Arquivos Analisados

A an√°lise √© restrita aos arquivos:

- Localizados em diret√≥rios `src`
- Pertencentes aos packages selecionados do monorepo
- Escritos em **JavaScript** e **TypeScript**

Arquivos de configura√ß√£o, testes, documenta√ß√£o, exemplos e artefatos de build s√£o **explicitamente exclu√≠dos**, a fim de reduzir ru√≠do e focar na l√≥gica central do sistema.

---

## ü§ñ Modelos de Linguagem Utilizados

Os modelos s√£o configurados e executados de forma modular. Exemplo de mapeamento:

```python
MODELS = {
    "qwen_small": "Qwen/Qwen2.5-Coder-3B-Instruct",
    "qwen": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "starcoder": "bigcode/starcoder2-7b"
}
```
---

## üì§ Formato da Sa√≠da

Os resultados s√£o armazenados em arquivos JSON, organizados por:

- Release do projeto
- Arquivo analisado
- Modelo de linguagem utilizado

Cada entrada segue o formato:

    
    {
    "code_smells": [
        {
        "name": "Nome do code smell",
        "category": "Categoria Refactoring Guru",
        "snippet": "Trecho de c√≥digo ou localiza√ß√£o",
        "justification": "Justificativa t√©cnica",
        "impact": "Impactos potenciais",
        "refactoring": "Sugest√£o de refatora√ß√£o"
        }
    ]
    }


Caso nenhum code smell seja identificado:

    
    {
    "code_smells": []
    }
    
---
## ‚ôªÔ∏è Execu√ß√£o Incremental e Reprodutibilidade

Para garantir reprodutibilidade e toler√¢ncia a falhas:

- Os resultados s√£o salvos ap√≥s o processamento de cada arquivo
- A execu√ß√£o pode ser retomada a partir do √∫ltimo checkpoint
- O arquivo incremental √© posteriormente consolidado como sa√≠da final

Essa abordagem evita retrabalho em caso de falhas ou interrup√ß√µes do ambiente.

---
## üìò Notebook Principal

O experimento completo est√° documentado no notebook:


üìì [`mastra_code_smell_analysis.ipynb`](./mastra_code_smell_analysis.ipynb)

Este notebook cont√©m todo o c√≥digo necess√°rio para reprodu√ß√£o do experimento, desde a prepara√ß√£o do ambiente at√© a gera√ß√£o do arquivo final de resultados.